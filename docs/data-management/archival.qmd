---
title: Disposition and Archival
---

## Data Disposal

Some data may need to be deleted to protect sensitive information or comply with regulations, data agreements, or funder requirements. This is often referred to as __data disposition__. If any of these requirements applies to a project, follow these best practices when deleting data:

* __Verify Requirements__: Confirm funder agreements and legal obligations regarding data retention and deletion.
* __Source Deletion__: Confirm with [IT](mailto:ithelp@rff.org) that the files were fully deleted in accordance with requirements (e.g., backup files).
* __Documentation__: Record when and how data was deleted.


## Data Archival

__Archiving__ refers to the secure, long-term storage of data in its final state, upon project completion.
Archiving often involves moving data to dedicated storage solutions designed for long-term retention, like archive servers or cloud storage.
This is sometimes referred to as “cold storage.” 

Archival is important because it:

* ensures long-term and secure storage to projects for reproducibility and reuse,
* improves organization, accessibility, and usability of both active and completed project files, and
* releases computational resources for active projects, reducing energy consumption and storage costs.

::: {.callout-note}
Archival takes place when projects are complete. To preserve the state of code and data at major milestones, such as journal article publication, see [LINK TO RELEVANT VERSION CONTROL SECTION / CLOUD STORAGE SECTION].
:::

### How to archive data at RFF

::: {.callout-note}
At RFF, archived files can still be accessed, read, and copied to active folders.
:::

When RFF data projects are archived, they are migrated to a new storage location, but are still configured to be accessible to certain team members.
The folder can be accessed in a way similar to the L drive, except that the files will be read-only to prevent accidental deletion or modification (they can still be copied or fully restored to the L drive).

#### Finalize data organization

* Delete obsolete and intermediate files. 
  * Ensure that irrelevant or outdated files are removed, so that only files necessary for reproduction or understanding are retained.
  * In general, intermediate data generated by code does not need to be archived, since it can be easily re-created from raw data and code.
* The files to be retained may vary by project, but in general should include:
  * Source (raw) data 
    * When possible, source data should be preserved without modification, as external data sources may be modified or become unavailable. 
    * However, for certain reliable data sources, citation and documentation may be sufficient (make sure to include the access date and dataset version).
    * If data were accessed via an API, see [section below](#archiving-source-data-and-apis).
  * Final analysis data
  * Results and visualizations
  * Code
  * Documentation

::: {.callout-note}
For additional guidance choosing which files to archive, see Best Practice: Decide what data to preserve.
:::

### Finalize documentation
* Finalize data and software documentation [LINK TO DOCUMENTATION SECTION]
* Create a text file called README and record the following information:
  * Project name and description
  * Project PI and contact information
  * List of staff responsible for data management and code development 
  * Associated final product, date of release, and DOI (if applicable)
  * Link to published data/code (if applicable)
  * License associated with final product
  * Approximate folder size (e.g., 5 GB)
  * List of researchers that should retain folder access
  * Nature of sensitive or proprietary data, if applicable
  * Any other important notes for navigating folder or using data/code

#### Coordinate with IT to ensure long-term folder access. 

Contact IT at [IThelp@rff.org](mailto:ithelp@rff.org) to arrange archival storage of the folder. Include the README with the email. IT will help to configure storage and folder access. 

## Archiving Source Data and APIs

If you [used an API](./data-storage-organization.qmd#accessing-raw-data-via-application-program-interfaces-apis) to access source data, the best course for archiving source data will vary based on project needs, dataset size, and nature of the data. Some options are:

* __Download to folder__: During the archival phase, download the source data in its current state and save it to the project folder to be archived.
* __Document__: Document the dataset version and access date. While not ideal for reproducibility, this is suitable in cases where the source data is large, reliable, and not likely to be modified. 
* __Download to cloud__: Use a repository service, such as Zenodo, to store source data as it existed when archiving the project. Source data accessed through an API can be [downloaded directly to a Zenodo repository](https://developers.zenodo.org/), without having to save files locally. This can be done through R ([zen4R](https://cran.r-project.org/web/packages/zen4R/zen4R.pdf)) or [python](https://pypi.org/project/zenodo-client/).

